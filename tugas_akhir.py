# -*- coding: utf-8 -*-
"""Tugas Akhir.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WanKEuZcmkBtmR2GEZNl8CjraEqQEpRs

# Proyek Analisis Data:

# **PreProcessing**

## Import Semua Packages/Library yang Digunakan
"""

!pip install -U imbalanced-learn

"""Install library yang tidak terdapat di google colab"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from google.colab import drive
drive.mount('/content/drive')
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import EarlyStopping
from imblearn.over_sampling import SMOTE

from sklearn.metrics import f1_score
from sklearn.model_selection import cross_val_score

"""Import semua library yang diperlukan

## Data Wrangling

### Gathering Data
"""

df = pd.read_csv('/content/drive/MyDrive/DBS/TUGAS ANALISIS DATA/Air-quality-dataset/PRSA_Data_20130301-20170228/PRSA_Data_Aotizhongxin_20130301-20170228.csv', index_col='No')
df.head()

"""Membaca data dengan pandas"""

df.columns

"""Melihat kolom apa saja yang terdapat di data"""

df.shape

"""Melihat ukuran data

**Insight:**
- Terdapat 18 kolom dengan 17 kolom fitur dan 1 kolom index dan 35.064 baris pada data kualitas udara

### Assessing Data
"""

df.info()

"""Melihat tipe data pada tiap kolom"""

df.isna().sum()

"""Melihat kolom-kolom yang memiliki nilai kosong"""

df.duplicated().sum()

"""Melihat apakah terdapat nilai duplikat"""

# Mengatur ukuran figure
plt.figure(figsize=(30, 16))

# Loop melalui setiap kolom dalam dataset
df_select_numeric = df.select_dtypes(include=['number']) # Hanya kolom numerik
for i, col in enumerate(df_select_numeric.columns, 1):
    plt.subplot(2, (len(df_select_numeric.columns) + 1) // 2, i)
    sns.boxplot(y=df_select_numeric[col])
    plt.title(f'Boxplot of {col}')
    plt.xlabel('')

plt.tight_layout()

"""Melihat sebaran boxplot dan apakah terdapat outlier di tiap kolom

**Insight:**
- Terdapat banyak sekali data kosong/missing value pada kolom-kolom tersebut
- Tidak terdapat duplikasi data
- Banyak sekali outlier pada data-data numerik

### Explore Data Analysis
"""

df_numeric = df[['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']]
df_numeric.describe()

"""Melakukan eksplorasi data numerik"""

# Set the figure size
plt.figure(figsize=(15, 10))

# Iterate through each numeric column and create a histogram
for i, col in enumerate(df_numeric.columns):
    plt.subplot(4, 3, i + 1)  # Adjust subplot layout as needed
    sns.histplot(df_numeric[col], kde=True)  # Added kde for density estimation
    plt.title(f'Histogram of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')

plt.tight_layout()
plt.show()

"""Melihat kembali sebaran data numerik

- Bagaimana curah hujan tiap bulannya dalam kurun waktu satu tahun
"""

rain_avg = df.groupby(['year', 'month'])['RAIN'].mean().reset_index()

# Buat pivot table untuk heatmap
rain_pivot = rain_avg.pivot(index='year', columns='month', values='RAIN')

# Plot menggunakan heatmap
plt.figure(figsize=(24, 12))
sns.heatmap(rain_pivot, cmap="Blues", annot=True, fmt=".8f")
plt.title("Rata-rata Curah Hujan (mm) dari Tahun ke Tahun Berdasarkan Bulan")
plt.xlabel("Bulan")
plt.ylabel("Tahun")
plt.show()

"""Membuat heatmap untuk melihat bagaimana sebaran jumlah hujan, dengan sumbu x adalah bulan dan sumbu y adalah tahun. Dapat dilihat hampir tiap bulan ke-7 menjadi puncak hujan

Analisis pertanyaan kedua
- Faktor apa yang menyebabkan curah hujan
"""

# Set the figure size
plt.figure(figsize=(15, 10))

# Iterate through each numeric column and create a histogram
for i, col in enumerate(df_numeric.columns):
    plt.subplot(4, 3, i + 1)  # Adjust subplot layout as needed
    sns.scatterplot(x=df['RAIN'], y=df_numeric[col])  # Added kde for density estimation
    plt.title(f'Scatter Plot of RAIN vs {col}')
    plt.xlabel('RAIN')
    plt.ylabel(col)

plt.tight_layout()
plt.show()

df_numeric.corr()

"""Melihat apakah terdapat korelasi fitur antara hujan dengan fitur yang lainnya. Tidak terdapat korelasi pada fitur RAIN dengan fitur yang lain

**Insight:**
- Melakukan pivot tabel untuk melihat rata-rata curah hujan tiap bulannya dalam kurun waktu 2013/2017
- Melihat korelasi antara hujan dengan atribut yang lain
"""

# Group data by year and month, then sum the rainfall
rain_sum = df.groupby(['year', 'month'])['RAIN'].mean().reset_index()

# Create the line chart
plt.figure(figsize=(12, 6))
for year in rain_sum['year'].unique():
    year_data = rain_sum[rain_sum['year'] == year]
    plt.plot(year_data['month'], year_data['RAIN'], label=str(year))

plt.xlabel("Month")
plt.ylabel("Total Rainfall (mm)")
plt.title("Rata-rata curah hujan dari tahun 2013/2017")
plt.legend()
plt.grid(True)
plt.show()

"""Membuat grafik sebaran hujan, untuk memudahkan pemahaman sebaran hujan. Dan dapat dilihat hampir tiap bulan ke-7 menjadi puncak jumlah hujan

### Cleaning Data
"""

df = df.drop(columns = ['station'])

"""Membuang kolom station, karena hanya 1 stasiun yang dianalisis"""

# Mengisi missing value kolom numerik dengan rata-rata
for col in ['PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'RAIN', 'WSPM']:
    df[col] = df[col].fillna(value=df[col].mean())

# Mengisi missing value kolom kategorik dengan modus
df['wd'] = df['wd'].fillna(df['wd'].mode()[0])

#Melihat kembali data apakah masih ada missing value
print(df.isna().sum())

"""Melakukan pembersihan data kosong dengan imputation, kolom numerik diisi dengan rata-rata dan kolom kategorik diisi dengan modus"""

# Imputasi outlier dengan IQR
def impute_outliers_iqr(df, column):
    Q1 = df[column].quantile(0.25)
    Q3 = df[column].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    df[column] = np.where(df[column] < lower_bound, lower_bound, df[column])
    df[column] = np.where(df[column] > upper_bound, upper_bound, df[column])

    return df

df_no_outlier = df.copy()
# Lakukan hal yang sama untuk kolom lain yang mengandung outlier
for col in ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'WSPM', 'PM2.5', 'RAIN']:
    df_no_outlier = impute_outliers_iqr(df_no_outlier, col)

"""Melakukan imputation pada outlier, mengganti nilai outlier dengan batas atas/bawah"""

# Mengatur ukuran figure
plt.figure(figsize=(30, 16))

# Loop melalui setiap kolom dalam dataset
df_select_numeric = df_no_outlier.select_dtypes(include=['number']) # Hanya kolom numerik
for i, col in enumerate(df_select_numeric.columns, 1):
    plt.subplot(2, (len(df_select_numeric.columns) + 1) // 2, i)
    sns.boxplot(y=df_select_numeric[col])
    plt.title(f'Boxplot of {col}')
    plt.xlabel('')

plt.tight_layout()

"""Melihat hasil pembersihan outlier"""

df_no_outlier['RAIN'].value_counts()

"""Data RAIN menjadi 0, menandakan tidak pernah ada hujan"""

rain = df['RAIN']
for index, value in rain.items():
  if value == 0:
    df.loc[index, 'RAIN_Category'] = 'Tidak Hujan'
  else:
    df.loc[index, 'RAIN_Category'] = 'Hujan'

"""Melakukan pendekatan dengan menambahkan kolom baru sebagai label kategori Hujan dan Tidak Hujan"""

df['RAIN_Category'].value_counts()

"""Melihat sebaran label"""

# Lakukan hal yang sama untuk kolom lain yang mengandung outlier
for col in ['PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP', 'WSPM', 'PM2.5']:
    impute_outliers_iqr(df, col)

"""Dilakukan kembali imputation pada data asli

**Insight:**
- Mengisi nilai kosong/missing value dengan rata-rata pada kolom numerik dan modus pada kolom kategorik
- Menangani outlier dengan metode imputation pada data copy, jika outlier bawah maka diisi dengan nilai batas bawah dan jika outlier atas maka diisi dengan nilai batas atas
- Semua kolom outlier yang diisi dengan batas atas dan bawah menunjukkan hilangnya fitur-fitur seperti pada kolom 'RAIN' ketika dilakukan imputation maka nilai rain hannya 0.0 itu akan merusak fakta dari data yang artinya tidak pernah ada hujan dari tahun 2013-2017, sehingga tidak perlu dilakukan imputation pada outlier
- Menambah kolom RAIN_Category sebagai kategori Hujan dan Tidak Hujan yang nantinya untuk dilakukan klasifikasi

# **Modeling**

## Encoding
"""

X = df.drop(['RAIN', 'RAIN_Category', 'year', 'hour'], axis=1)
y = df['RAIN_Category']

"""Memisahkan kolom target dan fitur. Selain itu membuang kolom yang tidak dibutuhkan 'year' dan 'hour' karena agar lebih fokus pada bulan dan harinya saja"""

X = pd.get_dummies(X, columns=['wd'], prefix='wd')
y_encoded = y.map({'Hujan': 1, 'Tidak Hujan': 0})

"""Melakukan Encoding pada fitur kategorik (wd) dengan onehot encoder dan melakukan pelabelan manual pada target

## Scaling Data
"""

# Scaling
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

"""Melakukan scaling data untuk model LSTM, digunakan MinMaxScaler karena sebarannya hanya 0-1

## SMOTE untuk model Random Forest
"""

smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)

print("Shape before SMOTE:", X.shape)
print("Shape after SMOTE:", X_resampled.shape)
print("\nClass distribution before SMOTE:\n", y.value_counts())
print("\nClass distribution after SMOTE:\n", y_resampled.value_counts())

"""SMOTE data atau penambahan baris sintetis pada data yang nantinya akan digunakan untuk model Random Forest

## Sliding Window untuk LSTM
"""

# Fungsi untuk membuat sequence (misal 3 waktu sebelumnya)
def create_sequences(X, y, time_steps=3):
    Xs, ys = [], []
    for i in range(len(X) - time_steps):
        Xs.append(X[i:i+time_steps])
        ys.append(y[i + time_steps])
    return np.array(Xs), np.array(ys)

X_seq, y_seq = create_sequences(X_scaled, y_encoded, time_steps=3)

"""Mempersiapkan Window untuk model LSTM, teknik yang digunakan adalah Sliding Window dengan tiap window berukuran 3

## Split Data
"""

#Split data Random Forest
X_train,X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

# Split data LSTM
X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm = train_test_split(X_seq, y_seq, test_size=0.2, random_state=42, stratify = y_seq)

"""Melakukan splitting data untuk tiap model, keduanya diperlakukan sama yaitu ukuran 80% data training dan 20% data testing

## Random Forest
"""

rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)

"""Melakukan fitting data pada model Random Forest dengan parameter default"""

y_pred = rfc.predict(X_test)

"""Melakukan prediksi data tes pada model Random Forest dengan SMOTE

## LSTM
"""

# Build model
lstm = Sequential()
lstm.add(LSTM(64, input_shape=(X_seq.shape[1], X_seq.shape[2])))
lstm.add(Dense(1, activation='sigmoid'))

lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])


# Buat callback
early_stop = EarlyStopping(
    monitor='val_loss',     # Pantau loss pada validation set
    patience=5,             # Hentikan setelah 5 epoch tanpa perbaikan
    restore_best_weights=True # Gunakan bobot terbaik (bukan dari epoch terakhir)
)

"""Membangun mempersiapkan model LSTM dengan layer pertama 64 dan layer kedua output 1, dengan fungsi aktivasi sigmoid untuk melakukan pengklasifikasian biner. Lakukan compile dengan optimizer adam dengan menghitung loss menggunakan binary cross entropy, dengan metrik perhitungan accuracy. Terakhir membuat callback untuk early stopping agar model tidak melakukan pelatihan sampai akhir ini bertujuan mempersingkat pelatihan dengan hasil terbaik."""

history = lstm.fit(
    X_train_lstm, y_train_lstm,
    epochs=100,
    batch_size=16,
    validation_split=0.1,
    callbacks=[early_stop]
)

"""Melakukan fitting pada model LSTM  dengan epoch 100 dan batchsize 16. Hasilnya model hanya melakukan 16 epoch, dikarenakan fungsi early stop yang digunakan.

# **Evaluasi Data**

## Random Forest
"""

cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            yticklabels=['Tidak Hujan', 'Hujan'],
            xticklabels=['Tidak Hujan', 'Hujan'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Melihat sebaran prediksi menggunakan confusion matriks, model dapat memprediksi kedua kelas secara baik"""

accuracy = classification_report(y_test, y_pred)
print(accuracy)

"""Hasil klasifikasi model Random Forest dengan SMOTE sangat memuaskan mencapai akuarasi 0.98

## LSTM
"""

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Plot training & validation loss values
plt.figure(figsize=(12, 6))
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model loss')
plt.ylabel('Loss')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

loss, accuracy = lstm.evaluate(X_test_lstm, y_test_lstm, verbose=0)
print(f'LSTM Test Accuracy: {accuracy:.4f}')
print(f'LSTM Test Loss: {loss:.4f}')

"""Grafik diatas adalah history hasil training pada model LSTM, model melakukan training yang bagus dimana bisa dilihat score training dan validation yang tidak beda secara signifikan"""

lstm_pred = lstm.predict(X_test_lstm)

"""Melakukan prediksi pada data test dengan model LSTM"""

lstm_pred_classes = (lstm_pred > 0.3).astype(int)

# Now pass the binary predictions to confusion_matrix
cm = confusion_matrix(y_test_lstm, lstm_pred_classes) # Use lstm_pred_classes here

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            yticklabels=['Tidak Hujan', 'Hujan'], # Ensure labels match the encoded values (0 and 1)
            xticklabels=['Tidak Hujan', 'Hujan']) # Ensure labels match the encoded values (0 and 1)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()

"""Melihat hasil prediksi data tes dengan confusion matriks, dapat dilihat model sulit menebak data hujan dikarenakan ketidak seimbangan data"""

accuracy = classification_report(y_test_lstm, lstm_pred_classes)
print(accuracy)

"""Melihat hasil klasifikasi, dimana akurasi sangat tinggi mencapai 0.96 tetapi pada kelas 1 atau Hujan score sangat rendah"""

# For Random Forest
f1_rfc = f1_score(y_test, y_pred, pos_label='Hujan') # Specify the positive class
print(f'Random Forest F1 Score: {f1_rfc:.4f}')

# For LSTM
f1_lstm = f1_score(y_test_lstm, lstm_pred_classes) # No need for pos_label if already binary (0/1)
print(f'LSTM F1 Score: {f1_lstm:.4f}')

"""Melakukan pengukuran dengan F1-score karena ketidak seimbangan data, dapat dilihat bahwa Random Forest dengan SMOTE jauh signifikan lebih baik ketimbang LSTM tanpa SMOTE

# **Inference**
"""

df[df['RAIN_Category'] == 'Hujan']

"""Mencari data dengan label hujan untuk dilakukan pengujian"""

#Prediksi Asli Hujan

data = {
        'month': [3],
        'day': [12],
        'PM2.5': [117.0],
        'PM10': [127.0],
        'SO2': [73.0],
        'NO2': [81.0],
        'CO': [1262.945145],
        'O3': [47.0],
        'TEMP': [6.4],
        'PRES': [1005.0],
        'DEWP': [-1],
        'WSPM': [2.2],
        'wd_E': [False],
        'wd_ENE': [False],
        'wd_ESE': [False],
        'wd_N': [True],
        'wd_NE': [False],
        'wd_NNE': [False],
        'wd_NNW': [False],
        'wd_NW': [False],
        'wd_S': [False],
        'wd_SE': [False],
        'wd_SSE': [False],
        'wd_SSW': [False],
        'wd_SW': [False],
        'wd_W': [False],
        'wd_WNW': [False],
        'wd_WSW': [False]
        }

data_df = pd.DataFrame(data)
pred = rfc.predict(data_df)
print(pred)

"""Menggunakan salah satu data dengan label Hujan, lalu dilakukan prediksi dengan menggunakan model Random Forest yang sudah dilatih sebelumnya, hasilnya seusai yaitu Hujan"""

# Scaling (pakai scaler dari training)
data_baru_scaled = scaler.transform(data_df)

# Bentuk ke [samples, time_steps, features]
X_input = np.expand_dims(data_baru_scaled, axis=0)  # (1, 3, jumlah_fitur)

# Prediksi probabilitas hujan
prediksi = lstm.predict(X_input)

# Output probabilitas (karena sigmoid)
print("Probabilitas hujan:", prediksi[0][0])

# Konversi ke label 0 atau 1 jika perlu
label = 1 if prediksi[0][0] > 0.3 else 0
print("Apakah akan hujan?", "Ya" if label == 1 else "Tidak")

"""Melakukan prediksi data yang sama pada pengujian menggunakan Random Forest sebelumnya. Data di scaling terlebih dahulu dan dilakukan prediksi. Prediksi melenceng dari label yang seharusnya."""